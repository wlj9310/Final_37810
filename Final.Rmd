---
title: "Final 37810"
author: "Shiting Zhu, Lijing Wang, Jingting Li"
date: "November 1, 2015"
output: pdf_document
---


## Question 1
## Metropolis Hastings
1. The algorithm is Metropolis-Hastings. We first choose the new phi based on the proposal function  

Step 0: Pick a start point $\phi_{0}$, which is a random number from uniform distribution (0,1)

Step 1: Pick a new candidate($\phi_{new}$) from the jumping distribution, which is Beta(c$\phi_{old}$,c(1-$\phi_{old}$)). Notice the $\phi_{new}$ cannot be either 0 or 1, otherwise it will loop in 0 or 1 forever. For this step we used a function called phi in the r code.

Step 2: Calculate the accaptance probability. Since the jumping distribution is not symmetric in this question, so 
$\frac{P(\phi_{new})}{P(\phi_{n})}$=$\frac{dbeta(\phi_{new},6,4)}{dbeta(\phi_{n},6,4)}$ and
$\frac{Q(\phi_{new}*|\phi_{n})}{Q(\phi_{n}|\phi_{new})}$=$\frac{dbeta(\phi_{new},c\phi_{n},c(1-\phi_{n}))}{dbeta(\phi_{n},c\phi_{new},c\phi_{new})}\\$
A($\phi_{n}$->$\phi_{new}$) = min(1,  $\frac{\frac{P(\phi_{new})}{P(\phi_{n})}}{\frac{Q(\phi_{new}*|\phi_{n})}{Q(\phi_{n}|\phi_{new})}}$).

```{r}
library(coda)
Alpha <- 6
Beta <- 4
# Use the proposal function to get new phi, noticeing phi cannot be 0 or 1
phi <- function(c,oldphi){
  newphi = 0
  # Making sure new phi is neither 0 nor 1
  while (newphi == 0 || newphi == 1){
  newphi = rbeta(1,c*oldphi,c*(1-oldphi))
  }
  return(newphi)
}

# 
run_metropolis_MCMC <- function(startvalue,c,iterations){
  chain = rep(0, iterations+1)
  chain[1] = startvalue
  for (i in 1:iterations){
    phi = phi(c,chain[i])
    posterior = dbeta(phi,Alpha,Beta)/dbeta(chain[i],Alpha,Beta)
    proposal = dbeta(phi,c*chain[i],c*(1-chain[i]))/dbeta(chain[i],c*phi,c*(1-phi))
    probab = posterior/proposal
    if (runif(1) < probab){
      chain[i+1] = phi
    }else{
      chain[i+1] = chain[i]
    }
  }
  return(chain)
}

startvalue = runif(1)
chain = run_metropolis_MCMC(startvalue,1, 10000)
acceptance = 1-mean(duplicated(chain))

par(mfrow=c(1,3))  #1 row, 3 columns

  traceplot(as.mcmc(chain), type="l", main = "Trace plot: c = 1", xlab="Step", ylab="y")
  acf(chain, main = "Acf plot: c = 1")
  hist(chain, main = "Histogram: c = 1", xlab="y")

Cs <- c(0.1, 2.5, 10)
result <- sapply(Cs, run_metropolis_MCMC, startvalue = startvalue,iterations = 10000)


graph <- function(Cs){
  n = length(Cs)
  par(mfrow = c(n, 3))
  for( i in 1:n ) {
  traceplot(as.mcmc(result[,i]), type="l", main = paste("Trace plot: c = ", Cs[i]), xlab="Step", ylab="y")
  acf(result[,i], main = paste("Acf plot: c = ", Cs[i]))
  hist(result[,i], main = paste("Histogram: c = ", Cs[i]), xlab="y")
  }
}

graph(Cs)
```


## Question 2 
## Gibbs Sampling

```{r}
Gibbs_<-function(x0,y0,iterations,B=5,burnIn=0)
## 5 parameters are needed in this function, with B=5 and burnIn=0 by default
{
  if(x0>0&&x0<B&&y0>0&&y0<B)
## to check whether the starting values are in the domain.    
  {
    x<-c(x0,rep(NA,iterations-1))
## Initialize the Markov chain    
    y<-c(y0,rep(NA,iterations-1))
## Initialize the Markov chain    
    for(i in 1:(iterations-1))
    {
      x[i+1]<-(-log(1-runif(1)*(1-exp(-y[i]*B)))/y[i])
## use inverse transform sampling to draw sample from conditional distribution 
## p(x^{i+1}|y^{i})   
      y[i+1]<-(-log(1-runif(1)*(1-exp(-x[i+1]*B)))/x[i+1])
## use inverse transform sampling to draw sample from conditional distribution 
## p(y^{i+1}|x^{i+1})     
    }
    if(burnIn>0)
    {
        x<-x[-(1:burnIn)]
        y<-y[-(1:burnIn)]
        print(length(x))
## discard the first bunch of draws for the burn-in process    
    }
    return(data.frame(x,y))
  }
 else
   stop("Initial values incorrect")
## print the information for incorrect starting values  
}
```

To estimate the marginal distribution generated from the conditional distributions using Gibbs sampling, we first pick up the starting values for $X$ and $Y$. Denote them as `x0` and `y0`. `iterations` stands for the number of draws we want to get from Gibbs sampling. `B` is the number given in the exercise, which is 5 here. `burnIn` is the number of draws we want to discard for the burn-in process, the default for `burnIn` is 0.  
  
In this case, both the conditional distribution of $X|Y$ and $Y|X$ are truncated exponential distribution. The domains of both conditional pdf's are $[0,B]$. So the starting values should satisfy $0<$`x0`$<B$ and $0<$`y0`$<B$. Therefore I put a restriction `if(x0>0&&x0<B&&y0>0&&y0<B)` on the input of starting values to check if they satisfy the requirement.  
  

Since $$ p(x|y)\propto ye^{-yx}, 0<x<B  $$ $$p(y|x)\propto xe^{-yx}, 0<y<B$$
Consider $p(x|y)$ only. To get samples using inverse transform sampling, first we need to figure out the normalizing constant for the conditional pdf and then the inverse function of cdf.  
  
The normalizing constant can be calculated using the formula $c=\frac{1}{\int f(x|y)\,\mathrm{d}x}$, if $p(x|y)$ $\propto$ $f(x|y)$. In this case, $f(x|y)=ye^{-yx}, 0<x<B$. Therefore $c=\frac{1}{\int_0^B ye^{-yx}\,\mathrm{d}x}=\frac{1}{1-e^{-By}}$.  

Then we start to calculate the cdf $H(x|y)$ for $X|Y$.   
We have $$p(x|y)=\frac{ye^{-yx}}{1-e^{-By}} , 0<x<B $$ 
Using the formula $F(x)=\int_{-\infty}^x p(z)\,\mathrm{d}z$, we get the cdf of $X|Y$: $$F(x|y)=\frac{1-e^{-xy}}{1-e^{-By}}, 0<x<B$$
  
Then we can write down the inverse function of $F(x|y)$, Denote as $F^{-1}(u|y), where  0\leq u\leq 1$.   
We have: $$F^{-1}(u|y)=-\frac{log(1-u(1-e^{-By}))}{y}, 0\leq u\leq 1$$  
According to inverse transform sampling, to draw a sample from $p(x|y)$, we first generate $u$ from $Unif[0,1]$, then $x=F^{-1}(u|y)$ is from the conditional distribution of X|Y. 
  
We draw samples from $p(y|x)$ using the same method.  
  
  
Now we start generating samples from p(x,y).  
  
Here I start Gibbs sampling with `x0` and `y0`, draw a value $x^{(1)}$ from the full conditional $p(x|$ `y0` $)$ using inverse transform sampling. Then use the updated $x^{(1)}$ to draw a sample from  $p(y|x^{(1)})$.  
  
To get more samples using Gibbs sampling, continually use the most updated values of $x$ and $y$ when generating samples from conditional distribution. To be more specific, generate $x^{(i+1)}$ from $p(x|y^{(i)})$ and $y^{(i+1)}$ from $p(y|x^{(i+1)})$. Repeat it for $n=$ `iterations` times.  
  
For the burn-in process, discard the first $m=$ `burnIn` samples from the Markov chain to reduce the influence of starting values on the Markov chain.  

